\documentclass[10pt,a4paper]{article}
\usepackage[utf8]{inputenc}
\usepackage[T1]{fontenc}
\usepackage[italian]{babel}
\usepackage{amsmath}
\usepackage{amsfonts} 
\usepackage{amssymb}
\usepackage{amsthm}
\usepackage{physics}
\usepackage{tikz}
\usetikzlibrary{backgrounds}
\usetikzlibrary{calc}
\tikzset{>=latex} % for LaTeX arrow head
\usepackage{xcolor}
\colorlet{veccol}{green!45!black}
\colorlet{myred}{red!90!black}
\colorlet{myblue}{blue!90!black}
\colorlet{mypurple}{blue!50!red!80!black!80}
\tikzstyle{vector}=[->,very thick,veccol]
\usepackage{pgfplots} % for the axis environment
\usetikzlibrary{calc} % to do arithmetic with coordinates
\usetikzlibrary{angles,quotes} % for pic
\usetikzlibrary{arrows.meta} % for arrow size
\usetikzlibrary{bending} % for arrow head angle
\tikzstyle{bend>}=[-{Latex[flex'=1,length=3,width=2.5]}]
\tikzstyle{bend<}=[{Latex[flex'=1,length=3,width=2.5]}-]
\usetikzlibrary{arrows.meta}
\tikzstyle{thin arrow}=[dashed,thin,-{Latex[length=4,width=3]}]
\usepackage[left=2cm,right=2cm,top=2cm,bottom=2cm]{geometry}
\author{Elisa Caruso}



\newtheorem{definition}{Definizione}[section]

\newtheorem{theorem}{Teorema}[section]
\newtheorem{lemma}[theorem]{Lemma}

\newcommand\normh[1]{\left\lVert#1\right\rVert}

\begin{document} 

\section{Introduzione}

%Devo dire che è una dim geometrica\\
%Devo dire che uso la dim di Buser e faccio solo i primi due teoremi di Bieb \\
%Devo enunciare i teoremi di Bieb \\



\section{Considerazioni preliminari}
Questo capitolo contiene gli strumenti fondamentali necessari per dare una dimostrazione geometrica dei primi due teoremi di Bieberbach. \\
Nella prima sezione definisco lo spazio euclideo n-dimensionale, il gruppo delle isometrie e descrivo una loro rappresentazione come composizione dell'applicazione di una matrice ortogonale e di una translazione; definisco poi il coniugio di due isometrie. \\
La lunghezza e la direzzione del vettore translazione di una data isometria mi danno immediatamente informazioni su come questa translazione agisce sui punti di $\mathbb{R}^n$; più complicato è invece capire, data una matrice ortogonale, come questa trasformi lo spazio. Nella seconda sezione definisco una funzione che mi dice quanto questa si discosta dalla matrice identità; definisco poi attraverso essa una scomposizione dello spazio in due spazi ortogonali. 




\section{Spazio euclideo $\mathbb{E}^n$ ed isometrie}
Considero lo spazio vettoriale n-dimensionale $\mathbb{R}^{n}$  \\
con il prodotto scalare  \hfill
\begin{minipage}{0.3\textwidth}
\[
  \vb{x} \cdot \vb{y} =  \sum_{i=1}^{n} x_i y_i    
\]
\end{minipage} \hfill
\begin{minipage}{0.3\textwidth}
$ \forall \vb{x} , \vb{y} \in \mathbb{R}^{n}$
\end{minipage} \\
E la norma associata   \hfill             
\begin{minipage}{0.3\textwidth}
\[
  \norm{\vb{x}} =  \sqrt{\vb{x} \cdot \vb{x}}
\]
\end{minipage} \hfill
\begin{minipage}{0.3\textwidth}
$ \forall \vb{x} \in \mathbb{R}^{n}$
\end{minipage} \newline
Definisco la distanza \hfill 
\begin{minipage}{0.3\textwidth}
\[ d(\vb{x}, \vb{y} ) = \norm{\vb{x-y}}\] 
\end{minipage} \hfill
\begin{minipage}{0.3\textwidth}
$ \forall \vb{x} , \vb{y} \in \mathbb{R}^{n}$
\end{minipage} \\
e l'angolo fra due vettori \hfill
\[ \angle (\vb{x},\vb{y}) = arccos \bigg( \frac{\vb{x} \cdot \vb{y}}{\norm{\vb{x}} \norm{\vb{y}}} \bigg) \in [0, \pi] \]
Imponendo questa metrica sullo spazio vettoriale $\mathbb{R}^n$ ottengo lo spazio euclideo $\mathbb{E}^n$. \\
E' noto dall'algebra lineare che gli automorfismi di $\mathbb{R}^n$ (ovvero le applicazioni lineari biettive da $\mathbb{R}^n$ in sé stesso) formano il gruppo $ GL(n, \mathbb{R}) $ con l'operazione di composizione di applicazioni lineari. Se compongo tali automorfismi con translazioni di vettori in $\mathbb{R}^n$ ottengo il gruppo affine $Aff(n, \mathbb{R}) \cong \mathbb{R}^{n} \rtimes GL(n, \mathbb{R})$. 

\begin{definition}
	Un'isometria di $\mathbb{E}^n$  è un funzione $ \alpha : \mathbb{R}^{n} \longrightarrow \mathbb{R}^{n} $  tale che $\forall \vb{x,y} \in \mathbb{R}^n $ vale 
	\[ d(\alpha(\vb{x}), \alpha(\vb{y})) = d(\vb{x} , \vb{y} )\]
\end{definition} 
Il seguente teorema è enunciato senza dimostrazione in quanto si tratta di un risultato classico dell'algebra lineare. 
\begin{theorem}
Data un'isometria di $\mathbb{E}^n $, questa può essere scritta in modo unico come composizione di una rotazione e di una traslazione
\[ \alpha : \mathbb{R}^{n} \longrightarrow \mathbb{R}^{n} \]
\[\vb{x} \longmapsto \vb{Ax + a} \]
dove $\vb{A} = rot( \alpha ) \in O(n) $ è detta componente di rotazione di $\alpha$ \\
e $\vb{a} = trans( \alpha ) \in \mathbb{R}^{n} $ è detta componente di traslazione di $\alpha$. 
\end{theorem}
\begin{lemma}
L'insieme delle isometrie di  $\mathbb{E}^{n} $  è un gruppo rispetto all'operazione di composizione di applicazioni lineari. Lo chiamiamo $Isom(n)$ e posso dire
\[ Isom(n) \cong \mathbb{R}^{n} \rtimes O(n) < \mathbb{R}^{n} \rtimes GL(n, \mathbb{R})
\]
\end{lemma}
All'interno di ogni gruppo è definito il commutatore di due elementi, posso quindi anche definirlo per $Isom(n)$.
\begin{lemma}
	Comunque prese  $ \alpha , \beta \in Isom(n)$, posso scriverle come $\alpha : \vb{x} \longmapsto \vb{Ax + a}$ e $\beta : \vb{x} \longmapsto \vb{Bx + b}$ \\
	Definisco il loro commutatore come  $ [ \alpha , \beta] = \alpha \beta \alpha^{-1} \beta^{-1}$. 
Valgono le due seguenti uguaglianze:
\begin{equation}
rot([ \alpha	, \beta ]) = \vb{[A, B]} = \vb{ABA^{-1}B^{-1}}
\end{equation}  
\begin{equation}
trans([ \alpha	, \beta ]) = \vb{(A-id)b+(id-[A,B])b+A(id-B)A^{-1}a }
\end{equation} 
\end{lemma}

\begin{proof}
	$ [ \alpha, \beta ](\vb{x}) = ( \alpha \beta \alpha^{-1} \beta^{-1} ) (\vb{x})$. \\
	Dato che $ \alpha : \vb{x} \longmapsto \vb{Ax + a}$ , allora sicuramente  $\alpha^{-1}: \vb{y} \longmapsto \vb{A^{-1}(y-a)}$.  \\
	Allo stesso modo, dato che $ \beta : \vb{x} \longmapsto \vb{Bx + b}$ , so che $\beta^{-1}: \vb{y} \longmapsto \vb{B^{-1}(y-b)}$. 
\begin{equation*}
\begin{split}
[ \alpha, \beta ](\vb{x}) = (\alpha \beta \alpha^{-1} \beta^{-1} ) (\vb{x})
& = (\alpha \beta \alpha^{-1})( \vb{B^{-1}(x-b)}) = \\ 
& = (\alpha \beta \alpha^{-1})( \vb{B^{-1}x- B^{-1}b }) = \\ 
& = (\alpha \beta)(\vb{A^{-1}( B^{-1}x- B^{-1}b -a)})= \\
& =  (\alpha \beta)(\vb{A^{-1} B^{-1}x- A^{-1}B^{-1}b -A^{-1}a})  = \\
& = (\alpha)(\vb{B(A^{-1} B^{-1}x- A^{-1}B^{-1}b -A^{-1}a) +b}) = \\
& = (\alpha)(\vb{BA^{-1} B^{-1}x-BA^{-1}B^{-1}b -BA^{-1}a +b}) = \\
& = \vb{A(BA^{-1} B^{-1}x-BA^{-1}B^{-1}b -BA^{-1}a +b) + a} = \\
& = \vb{A(BA^{-1} B^{-1}x-BA^{-1}B^{-1}b -BA^{-1}a +b) + a} = \\
& = \vb{ABA^{-1} B^{-1}x-ABA^{-1}B^{-1}b -ABA^{-1}a +Ab + a }
\end{split}
\end{equation*}
Quindi ho che $ rot([ \alpha , \beta ]) = \vb{ABA^{-1} B^{-1} }$ e
\begin{equation*}
\begin{split}
trans([ \alpha, \beta ]) & = \vb{-ABA^{-1}B^{-1}b -ABA^{-1}a +Ab + a }= \\
& = \vb{Ab + a -ABA^{-1}B^{-1}b -ABA^{-1}a }= \\
& = \vb{(A-id)b + b + a -ABA^{-1}B^{-1}b -ABA^{-1}a} = \\
& = \vb{(A-id)b + (id-[A,B])b + a - ABA^{-1}a} = \\
& = \vb{(A-id)b + (id-[A,B])b + (id- ABA^{-1})a }= \\
& = \vb{(A-id)b + (id-[A,B])b + A(id- B)A^{-1}a} 
\end{split}
\end{equation*}	
\end{proof}

\section{"Misura di rotazione"}
\begin{definition}
Comunque preso  $  \vb{A} \in O(n) $  definisco
\[ m(\vb{A}) = \max \bigg\{ \frac{\norm{\vb{Ax-x}}}{\norm{\vb{x}}} \bigg|  \vb{x} \in \mathbb{R}^{n}-\vb{0} \bigg\} \]
\end{definition}
Questa funzionemi dice quanto una data matrice ortogonale si comporta in modo diverso dalla matrice identità; descrive infatti quanto al massimo un vettore unitario viene "spostato" dall'azione di tale matrice. 
\begin{lemma}
La precedente è una buona definizione e inoltre vale
\[ m(\vb{A}) = \max \bigg\{ \norm{\vb{Ax-x}} \bigg|  \vb{x} \in \mathbb{R}^{n} \land \norm{\vb{x}} = 1 \bigg\} \]
\end{lemma}

\begin{proof}
$ \forall \vb{x} \in \mathbb{R}^{n}-\vb{0}$  $ \exists \vb{y} \in \mathbb{R}^{n}-\vb{0} $ tale che \hfill $\vb{x} = \lambda \vb{y} , \lambda \in \mathbb{R} \land \norm{\vb{y}} = 1 $. 

\[ \frac{\norm{\vb{Ax-x}}}{\norm{\vb{x}}} = \frac{\norm{\vb{A}\lambda \vb{y}-\lambda \vb{y}}}{\norm{\lambda \vb{y}}} =   \frac{|\lambda| \norm{\vb{Ay-y}}}{|\lambda| \norm{\vb{ y}}} = \norm{\vb{Ay-y}} \]

\[ m(\vb{A}) = \max \bigg\{ \norm{\vb{Ax-x}} \bigg|  \vb{x} \in \mathbb{R}^{n} \land \norm{\vb{x}} = 1 \bigg\}\] L'insime $\vb{x} \in \mathbb{R}^{n} \land \norm{\vb{x}} = 1 $  è un compatto in  $\mathbb{R}^{n}$, quindi per il teorema di Weierstrass esiste una $\vb{x} \in \mathbb{R}^{n} \land \norm{\vb{x}} = 1$ che mi verifica il max. 
\end{proof}

\begin{lemma}
Comunque preso $ \vb{x} \in \mathbb{R}^{n}$  vale  \[ \norm{\vb{Ax-x}} \leq m(\vb{A}) \norm{\vb{x}} \]
\end{lemma}

\begin{proof}
Infatti vale $\forall \vb{x} \in \mathbb{R}^{n}-\vb{0}$  e vale anche per  $\vb{x}=0$
\end{proof}
Una volta defiinta la funzione $m$ posso definire il sottoinsieme di $\mathbb{R}^n$ che contiene tutti e soli i vettori che realizzano il massimo nella sua definizione. 
\begin{definition}
\[ E_{\vb{A}} := \{ \vb{x} \in \mathbb{R}^{n} :  \norm{\vb{Ax - x}} = m(\vb{A}) \norm{\vb{x}}\} \]
\end{definition}

\begin{lemma}
$E_A$ è un sottospazio di $\mathbb{R}^{n}$ non banale ed A-invariante
\end{lemma} 
\begin{proof}
\begin{itemize}
\item $\vb{0} \in E_{\vb{A}} $  
\item $\forall \vb{x} \in E_{\vb{A}}, \forall \lambda \in \mathbb{R}$ \\
$\vb{x} \in E_{\vb{A}} \Longrightarrow \norm{\vb{Ax-x}} = m(\vb{A})\norm{\vb{x}} \Longrightarrow \norm{\vb{A} \lambda \vb{x} -\lambda \vb{x}}= | \lambda | m(\vb{A}) \norm{\vb{x}}  \Longrightarrow \lambda \vb{x} \in E_{\vb{A}} $
\item $\forall \vb{x, y} \in E_{\vb{A}} $ voglio verificare che $\vb{x+y, x-y} \in E_{\vb{A}}$ \\
$\vb{x} \in E_{\vb{A}} \Longrightarrow \norm{\vb{Ax-x}} = m(\vb{A})\norm{\vb{x}}$ \\
$\vb{y} \in E_{\vb{A}} \Longrightarrow \norm{\vb{Ay-y}} = m(\vb{A})\norm{\vb{y}}$ 
\begin{equation} 
\begin{split}
& \norm{\vb{A(x+y) - (x+y)}}^2 + \norm{\vb{A(x-y) - (x-y)}}^2  = \norm{\vb{Ax - x + Ay -y}}^2 + \norm{\vb{Ax - x -(Ay -y)}}^2 = \\
& = 2 \norm{\vb{Ax-x}}^2 + 2 \norm{\vb{Ay -y}}^2  = 2( \norm{\vb{Ax-x}}^2 + \norm{\vb{Ay-y}}^2) = 2m(\vb{A})^2(\norm{\vb{x}}^2 + \norm{\vb{y}}^2) 
\end{split}
\end{equation}
Da (3) segue 
\begin{equation} 
\begin{split}
2m(\vb{A})^2(\norm{\vb{x}}^2 + \norm{\vb{y}}^2) & = \norm{\vb{A(x+y) - (x+y)}}^2 + \norm{\vb{A(x-y) - (x-y)}}^2 \leq m(\vb{A})^2(\norm{\vb{x+y}}^2 + \norm{\vb{x-y}}^2) \\ 
& = m(\vb{A})^2(\norm{\vb{x+y}}^2 + \norm{\vb{x-y}}^2)  = 2m(\vb{A})^2(\norm{\vb{x}}^2 + \norm{\vb{y}}^2)
\end{split}
\end{equation}
Quindi il segno di disuguaglianza in (4) è un'uguaglianza, in particolare 
\[   \norm{\vb{A(x+y) - (x+y)}}^2 + \norm{\vb{A(x-y) - (x-y)}}^2  = m(\vb{A})^2(\norm{\vb{x+y}}^2 + \norm{\vb{x-y}}^2)  \]
Spostando i termini da parte a parte ottengo
\[ \norm{\vb{A(x+y) - (x+y)}}^2 - m(\vb{A})^2 \norm{\vb{x+y}}^2=  m(\vb{A})^2 \norm{\vb{x-y}}^2 - \norm{\vb{A(x-y) - (x-y)}}^2 \]
\begin{equation} 
\begin{split}
\bigg( \norm{\vb{A(x+y) - (x+y)}} & + m(\vb{A})\norm{\vb{x+y}} \bigg) \bigg( \norm{\vb{A(x+y) - (x+y)}} - m(\vb{A}) \norm{\vb{x+y}} \bigg) = \\
& -\bigg( \norm{\vb{A(x-y) - (x-y)}} + m(\vb{A})\norm{\vb{x-y}} \bigg) \bigg( \norm{\vb{A(x-y) - (x-y)}} - m(\vb{A}) \norm{\vb{x-y}} \bigg)
\end{split}
\end{equation}
Distinguiamo alcuni casi: 
\begin{itemize}
\item Se $\vb{A} = \vb{id} \Rightarrow m(\vb{A}) = 0 \Rightarrow E_{\vb{A}} = \mathbb{R}^{n}$  ed in quel caso ho chiuso la dimostrazione.
\item Se $\vb{x} = \vb{y}$ o $\vb{x} = \vb{-y}$  ho già chiuso la dimostrazione per il punto precedente (rispettivamente con $\lambda = +1$ e $\lambda = -1$). 
\item Nei restanti casi posso osservare che nell'equazione (5) il primo fattore a sinistra dell'uguaglianza è strettamente positivo, mentre il secondo fattore è $\leq 0 $. Allo stesso modo a destra dell'uguaglianza ho un meno che mi modifica il segno del prodotto; il primo fattore è strettamente positivo ed il secondo è $\leq 0 $. \\ L'uguaglianza in (5) deve quindi per forza coincidere con $0=0$ e questo mi implica 
\begin{equation*}
  \left\{
    \begin{aligned}
      & \norm{\vb{A(x+y) - (x+y)}} = m(\vb{A})\norm{\vb{x+y}} \\
      & \norm{\vb{A(x-y) - (x-y)}} = m(\vb{A})\norm{\vb{x-y}} 
    \end{aligned}
  \right.
\end{equation*}

$\Longrightarrow \vb{x+y, x-y} \in E_{\vb{A}} $ 
\end{itemize}  
Ho concluso la dimostrazione del fatto che $E_{\vb{A}}$ è un sottospazio vettoriale di $\mathbb{R}^n $
\item Mostro che $E_{\vb{A}}$ è non banale. 
\[ m(\vb{A}) = \max \bigg\{ \norm{\vb{Ax-x}} \bigg|  \vb{x} \in \mathbb{R}^{n} \land \norm{\vb{x}} = 1 \bigg\} \] 
 L'insieme degli $\vb{x} \in \mathbb{R}^{n} \land \norm{\vb{x}} = 1$ è un compatto; l'applicazione $ \vb{x} \mapsto \norm{\vb{Ax-x}}$ è continua in quanto composizione di funzioni continue, quindi sicuramente esiste un $\vb{x} \in \mathbb{R}^{n} \land \norm{\vb{x}} = 1$  che mi verifica il massimo. In particolare $\vb{x} \neq \vb{0}$  (perché ha norma 1) e 
\[ \norm{\vb{Ax - x}} = m(\vb{A}) = m(\vb{A})\norm{\vb{x}} \Longrightarrow \vb{x} \in E_{\vb{A}}\]
\item Mostro che $E_{\vb{A}}$ è $\vb{A}$-invariante. \\
$\forall \vb{x} \in E_{\vb{A}}$  voglio mostrare che $\vb{Ax} \in E_{\vb{A}}$ \\
$\vb{x} \in E_{\vb{A}} \Longrightarrow \norm{\vb{Ax-x}} = m(\vb{A})\norm{\vb{x}} $ \\
Dato che $\vb{A} \in O(n)$ ho la seguente catena di uguaglianze:\\
$ \norm{\vb{A(Ax) - Ax }} =  \norm{\vb{A(Ax-x)}} = \norm{\vb{Ax - x}} = m(\vb{A})\norm{\vb{x}} = m(\vb{A})\norm{\vb{Ax}} \Longrightarrow \vb{Ax} \in E_{\vb{A}}$
\end{itemize} 
\end{proof}
\begin{lemma}
$E_{\vb{A}}$ sottospazio vettoriale di $\mathbb{R}^n $ non banale, quindi posso definire il suo complemento ortogonale $E^{\perp}_{\vb{A}} \neq \mathbb{R}^n$ ed anche questo è $\vb{A}$-invariante. 
\end{lemma} 

\begin{definition}

\[ m^{\perp}(\vb{A}) = \begin{cases} 
      \max \bigg\{ \frac{\norm{\vb{Ax-x}}}{\norm{\vb{x}}} \bigg|  \vb{x} \in E^{\perp}_{\vb{A}} - \vb{0} \bigg\}  &  se   E^{\perp}_{\vb{A}} \neq {\vb{0}} \\
      0 & se   E^{\perp}_{\vb{A}} = {\vb{0}} \\
      
   \end{cases}
\]

\end{definition}

\begin{lemma}
$m^{\perp}(\vb{A}) < m(\vb{A})$ se $\vb{A \neq id} $\\
$m^{\perp}(\vb{A}) = m(\vb{A}) = 0$ se $\vb{A = id}$

\end{lemma}

\begin{proof}
\begin{itemize}
\item Se $\vb{A = id} \Longrightarrow m(\vb{A}) = 0 \land E_{\vb{A}} = \mathbb{R}^n$. Quindi $E^{\perp}_{\vb{A}} = {0} \Longrightarrow m^{\perp}(\vb{A}) = 0$

\item Se $\vb{A \neq id}$ \\
\[ m(\vb{A}) = \max \bigg\{ \frac{\norm{\vb{Ax-x}}}{\norm{\vb{x}}} \bigg|  \vb{x} \in \mathbb{R}^{n}-\vb{0} \bigg\} 
\geq \max \bigg\{ \frac{\norm{\vb{Ax-x}}}{\norm{\vb{x}}} \bigg|  \vb{x} \in E^{\perp}_{\vb{A}} - \vb{0} \bigg\} =  m^{\perp}(\vb{A}) \]
Se valesse $m(\vb{A}) = m^{\perp}(\vb{A}) \Longrightarrow \exists \vb{x} \in E^{\perp}_{\vb{A}} - \vb{0} : \norm{\vb{Ax-x}} = m(\vb{A})\norm{\vb{x}} \Longrightarrow \vb{x} \in E_{\vb{A}}$  ma questo implica $\vb{x} \in E_{\vb{A}} \cap E^{\perp}_{\vb{E}} = {\vb{0}} \Longrightarrow \vb{x = 0} $;  questo è però assurdo perché ho imposto che $x\vb{ \neq 0}$ 
\end{itemize}
\end{proof}

\begin{lemma}
$\forall \vb{x} \in \mathbb{R}^n $ posso scrivere $\vb{x}$ in modo unico in decomposizione ortogonale. \\
$\vb{x} = \vb{x}^E + \vb{x}^{\perp}$ dove $\vb{x}^E \in E_{\vb{A}}$ e $\vb{x}^{\perp} \in E^{\perp}_{\vb{A}}$ \\
Valgono inoltre le proprietà:
\[ \norm{\vb{Ax}^E - \vb{x} }= m(\vb{A})\norm{\vb{x}^E} \] \[\norm{\vb{Ax}^{\perp} - \vb{x}} \leq m(\vb{A}) \norm{\vb{x}^{\perp}} \]
\end{lemma}

\begin{lemma}
 $\forall \vb{ A, B} \in O(n)$ vale la disuguaglianza $ m([\vb{A,B}]) \leq 2m(\vb{A})m(\vb{B})$ 
\end{lemma}

\begin{proof}



\[ [\vb{A,B}] - \vb{id} = \vb{ABA^{-1}B^{-1} - id }= \vb{(AB -BA)A^{-1}B^{-1} }= [ \vb{ (A-id)(B-id) - (B-id)(A-id)}] \vb{A^{-1}B^{-1}} = \]
 \[  = \vb{( A-id)(B-id) A^{-1}B^{-1} -  (B-id)(A-id) A^{-1}B^{-1}} \]
 
 
 \begin{equation} 
\begin{split}
\norm{\vb{([A,B] - id )x}} & \leq \norm{\vb{ ( A-id)(B-id) A^{-1}B^{-1}x}} +  \norm{\vb{(B-id)(A-id) A^{-1}B^{-1}x}} \leq \\
& \leq m(\vb{A}) \norm{\vb{(B-id) A^{-1}B^{-1}x}} + m(\vb{B}) \norm{\vb{(A-id) A^{-1}B^{-1}x}} \leq \\ 
& \leq m(\vb{A})m(\vb{B})\norm{\vb{A^{-1}B^{-1}x}} + m(\vb{B})m(\vb{A}) \norm{\vb{A^{-1}B^{-1}x}}
\end{split}
\end{equation}

Dato che $ \vb{A,B} \in O(n)$ posso scrivere $\norm{\vb{A^{-1}B^{-1}x}} = \norm{\vb{x}} $ , quindi 

\begin{equation}
  \norm{\vb{([A,B] - id )x}}  \leq 2m(\vb{A})m(\vb{B})\norm{\vb{x}}
\end{equation} 
Quindi segue immediatamente la tesi. 
\end{proof}
\pagebreak
\section{Primo teorema di Bieberbach}
\begin{theorem}
Dato un gruppo discreto di isometrie di $\mathbb{R}^n$ a dominio fondamentale compatto, questo contiene $n$ translazioni linearmente indipendenti. 
\end{theorem}
In questo elaborato utilizzo la seguente definizione di gruppo cristallografico:
\begin{definition}
Sia $\Gamma$ un sottogrupo di $Isom(n)$, dico che è un gruppo cristallografico $n$-dimensionale se valgono le seguenti condizioni:
\begin{enumerate}
	\item $ \forall t \in \mathbb{R} : t > 0 $  esistono solo un numero finito di $\alpha \in \Gamma $  tali che  $|a| \leq t$

	\item $ \exists d \in \mathbb{R}: \forall \vb{x} \in \mathbb{R}^n   \exists \alpha \in \Gamma : \norm{\vb{a-x}}\leq d $
\end{enumerate}
\end{definition}
Se considero lo spazio topologico $\mathbb{R}^n$ con la metrica data dalla distanza euclidea ed un gruppo di isometrie che agisce su di esso, la condizione 1. implica che agisce in modo propriamente discontinuo, mentre la condizione 2. significa che ha dominio fondamentale limitato. Dato uno spazio topologico $X$ ed un gruppo $G$ che agisce su di esso, un dominio fondamentale è un sottoinsieme di $X$ che contiene uno ed un solo punto di ogni orbita dell'azione.\\

Posso quindi rifrasare il primo teorema di Bieberbach come 

\begin{theorem}
Ogni gruppo gristallografico $n$-dimensionale contiene $n$ translazioni linearmente indipendenti
\end{theorem}

\section{Mini Bieberbach} 
\begin{theorem}{Mini Bieberbach.}
Sia $\Gamma$ un gruppo cristallografico di $\mathbb{E}^n$ \\
$ \forall \vb{u} \in \mathbb{R}^n : \norm{\vb{u}} = 1,   \forall \epsilon , \delta >0 $ \hfill  $   \exists \beta \in \Gamma $ che soddisfa \hfill
\begin{minipage}{0.3\textwidth} 
\begin{enumerate}
\item $\vb{a} \neq 0$ 
\item $ \angle (\vb{u, a}) \leq \delta $
\item $ m(\vb{A}) \leq \epsilon$ 
\end{enumerate}
\end{minipage}
\end{theorem}

\begin{proof}
Per la seconda proprietà dei gruppi cristallografici so che $ \exists d \in \mathbb{R} : \forall k \in \mathbb{N} $ $  \exists \beta_k \in \Gamma : $ \\
$ \; \beta_k \vb{x} = \vb{B_k x + b_k}  \; \; \land \; \;\norm{\vb{b_k - ku }} \leq d $ 
\\
Se $k \longrightarrow \infty$ allora sicuramente $ \norm{\vb{b_k}} \longrightarrow \infty$.  \\
Infatti se, per assurdo, questo non fosse vero $\exists M \in \mathbb{R} : \norm{\vb{b_k}} \leq M $   $  \forall k \in \mathbb{N} $
\[ d \geq \norm{\vb{b_k - ku}} \geq | \norm{\vb{b_k}} - k | \]
Nella disequazione  precedente, se la successione è limitata allora l'ultimo termine diverge ma questo è assurdo perché è maggiorato da $d$. \\



Considero ora la successione degli angoli fra il vettore $\vb{u}$ e $\vb{b}_k$, voglio mostrare che la loro ampiezza tende a 0. 
\begin{minipage}{0.5\textwidth}
    \begin{tikzpicture}[line cap=round]
  \coordinate (O) at (0,0);
  \coordinate (A) at (6, 0);
  \coordinate (B) at (5,2.4);
  \coordinate (A-B) at ($(A)-(B)$);
  

  \draw[vector,myred] (O) -- (A) node[midway,below] {$k \vb{u}$};
  \draw[vector,myblue] (O) -- (B) node[midway,above left=-2] {$\vb{b_k}$};
  \draw[vector,mypurple] (A) -- (B) node[above right=-3] {$\vb{b_k}-k\vb{u}$};
  \pic[draw,"$\theta_k$",angle radius=20,angle eccentricity=1.25] {angle=A--O--B}; 
  \pic[draw,"$\gamma_k$",angle radius=20,angle eccentricity=1.25] {angle=B--A--O};  
\end{tikzpicture}
\end{minipage}\hfill
\begin{minipage}{0.5\textwidth}
	\[ \angle (\vb{u , b_k}) = \angle (\vb{ku, b_k}) = : \theta_k \]
\[ \frac{\norm{\vb{b_k}}}{sin(\gamma_k)} = \frac{\norm{\vb{b_k} - k\vb{u}}}{sin(\theta_k)}  \leq \frac{d}{sin(\theta_k)} \]
\[  sin(\theta_k) \leq \frac{sin(\gamma_k)d}{\norm{\vb{b_k}}} \longrightarrow 0 \Longrightarrow \theta_k \longrightarrow 0 \]
\end{minipage}\\


Ho definito la successione ${ \{\beta_k \}}_{k \in \mathbb{N}}$  con  $\beta_k \vb{x = B}_k \vb{x + b}_k$   $\beta_k \in \Gamma \Longrightarrow \vb{B}_k \in O(n)$  \\
$O(n)$  è compatto e ${ \{\vb{B}_k \} }_{k \in \mathbb{N}}$ successione in  $O(n)$  ammette quindi almeno un punto di accumulazione per il teorema di Bolzano-Weierstrass. \\
Estraggo da ${ \{ \vb{B}_k \}}_{k \in \mathbb{N}}$  una sottosuccessione  $ { \{ \vb{A}_k \} }_{k \in \mathbb{N}} = { \{ \vb{B}_{k_j} \} }_{j \in \mathbb{N}}$  convergente.  \\
La funzione  $ m: O(n) \longrightarrow \mathbb{R}$  è continua in quanto composizione di funzioni continue ($ \vb{A} \mapsto \max{\norm{\vb{Ax-x}}} $), quindi con $i,j \in \mathbb{B} \longrightarrow \infty $ sicuramente $m(\vb{A}_j \vb{A}^{-1}_i) \longrightarrow m(\vb{id}) = 0 $ \\
Associata a questa sottosuccessione ho ovviamente una sottosuccessione di ${ \{\beta_k \}}_{k \in \mathbb{N}}$ che chiamo ${ \{\alpha_k \}}_{k \in \mathbb{N}}$ con  $\alpha_k \vb{x = A}_k \vb{x + a}_k$ \\


Dato che valgono tutte le proprietà di cui sopra, è immediato verificare che $\exists i,j \in \mathbb{N} $  tali che  $ i < j$  e che valgano contemporaneamente
\[ \begin{cases} \angle(u, \vb{a}_j ) \leq \frac{\delta}{2} \\
\norm{\vb{a}_i} \leq \frac{\delta}{4}\norm{\vb{a}_j} \\
m( \vb{A}_j \vb{A}^{-1}_i ) \leq \epsilon  \end{cases} \]
Considero l'isometria definita da $\alpha \in \Gamma$ come 
\[ \alpha : x \longmapsto \alpha_j \alpha^{-1}_i \vb{x} = \vb{A}_j \vb{A}^{-1}_i \vb{x} + \vb{a}_j - \vb{A}_j \vb{A}^{-1}_i \vb{a}_i\]
Questa isometria verifica tutte le proprietà richieste dalla tesi

\begin{itemize}
\item \'E ovvio che $m(\vb{A}) = m(\vb{A}_j \vb{A}^{-1}_i) \leq \epsilon$ 
\item Verifico  $\vb{a}= \vb{a}_j - \vb{A}_j \vb{A}^{-1}_i \vb{a}_i \neq 0$ 
\[ \norm{\vb{a}_j - \vb{A}_j \vb{A}^{-1}_i \vb{a}_i} \geq \bigg| \norm{\vb{a}_j} - \norm{ \vb{A}_j \vb{A}^{-1}_i \vb{a}_i } \bigg| \geq \bigg| \norm{\vb{a}_j } + \norm{\vb{a}_i} \bigg| \geq \norm{\vb{a}_i} \bigg| \frac{4}{\delta} -1 \bigg| \]
$\norm{\vb{a}_i} \neq 0 \Longrightarrow \vb{a} \neq 0$
 
\item Verifico $ \angle (\vb{u, a})  = \angle (\vb{u} , \vb{a_j - A_j A_i^{-1} a_i} ) \leq \delta $. 
\begin{equation}
\angle (\vb{u} , \vb{a_j - A_j A_i^{-1} a_i} ) \leq \angle (\vb{u} , \vb{a_j}) + \angle(\vb{a_j}, \vb{a_j- A_j A_i^{-1} a_i} ) 
\end{equation}

Dato che $ \norm{\vb{a}_i} \leq \frac{\delta}{4}\norm{\vb{a}_k}$, la punta del vettore $\vb{a}_j - \vb{A_j A_i^{-1} a_i}$ cade all'interno du una palla n-dimensionale che ha come centro la punta di $\vb{a}_j$ e raggio $r = \frac{\delta}{4}\norm{\vb{a}_k}$\\
\begin{center}
\begin{tikzpicture}[line cap=round]
  \coordinate (O) at (0,0);
  \coordinate (A) at (9,0);
  \coordinate (B) at (1.5,1);
  \coordinate (C) at ($(O)-(B)$);
  \coordinate (U) at (1, -1.5);
  \coordinate (X) at ($(A)+(C)$);
  \draw[vector] (O) -- (A) node[midway,above] {$\vb{a}_j$};
  \draw[vector,red] (O) -- (B) node[above right = -2] {$\vb{A_j A_i^{-1} a_i}$};
  \draw (A) circle (2)node[right]{$r = \frac{\delta}{4}\norm{\vb{a}_k}$};
  \draw[vector, black] (O) -- (U) node[midway, below] {$ \vb{u} $};
  \draw[vector,red] (A) -- (X);
  \draw[vector] (O) -- (X)node[midway,below] {$\vb{a}_j - \vb{A_j A_i^{-1} a_i}$};
\end{tikzpicture}
\end{center} 

Considero una situaizone come quella nel disegno precedente; \\ 
\begin{minipage}{0.3\textwidth}
$\forall \rm P$ scelto all'interno della circonferenza \\ $ \widehat{PAO} \leq \widehat{TAO} $ 
\[ \frac{\overline{TO}}{sin( \widehat{TAO}) } = \frac{\overline{AO}}{sin( \widehat{ATO}) } \] 
Quindi
\[ sin(\widehat{PAO}) \leq sin( \widehat{TAO})= \frac{\overline{TO}}{\overline{AO}} = \frac{\delta}{4}\]
\end{minipage} \hfill
\begin{minipage}{0.6\textwidth}
\begin{tikzpicture}
  \def\r{2} % radius
  \def\q{-7} % distance center-external point q = |OQ|
  \def\x{{\r^2/\q}} % Q x coordinate
  \def\y{{\r*sqrt(1-(\r/\q)^2}} % Q y coordinate
  \coordinate (O) at (0,0); % circle center O
  \coordinate (Q) at (\q,0); % external point Q
  \coordinate (P) at (\x,\y); % point of tangency, P
  \coordinate (X) at (1, 1);
  \draw[blue,thick] (O) circle(\r);
  \draw[green,thick] (Q) -- (P);
  \draw[green,thick] (P) -- (O);
  \draw[green,thick] (O) -- (Q);
  \draw (O) -- (X);
  \draw (Q) -- (X);
  \fill(O) circle(0.05) node[below right] {O};
  \fill(Q) circle(0.05) node[below left] {A};
  \fill(P) circle(0.05) node[above=3] {T};
  \fill(X) circle(0.05) node[above=3,right=4] {P};
  \pic [draw, angle radius=4, angle eccentricity=4] {right angle = O--P--Q};
\end{tikzpicture}
\end{minipage}

So quindi che 
\begin{equation}
sin(\angle(\vb{a_j}, \vb{a_j- A_j A_i^{-1} a_i} ) ) \leq \frac{\delta}{4} \Longrightarrow \angle(\vb{a_j}, \vb{a_j- A_j A_i^{-1} a_i} ) \leq \frac{\delta}{4} + o \bigg( \frac{\delta^2}{16} \bigg) \leq \frac{\delta}{2}
\end{equation}
E (9) insieme con (8) e $ \angle(\vb{u}, \vb{a}_j) \leq \frac{\delta}{2}$ implica che 
\[ \angle (\vb{u, a}) \leq \delta \]
\end{itemize}


\end{proof}


\begin{theorem}
 Comunque scelta $\alpha \in \Gamma$:  $x \longmapsto \vb{Ax +a} $  tale per cui $m(\vb{A}) \leq \frac{1}{2} $, questa isometria è una traslazione pura 
\end{theorem}

\begin{proof}
 Se $m(\vb{A}) = 0 \Longrightarrow A = id \Longrightarrow \alpha$ è una traslazione pura. \\
 
 
\begin{minipage}{0.5\textwidth}
Fra le isometrie in $\Gamma$ che soddisfano la condizione  $ 0 < m(\vb{A}) \leq \frac{1}{2}$  scelgo quella che ha $\norm{\vb{a}}$ minimo (posso farlo perché vale la condizione (1) sugli elementi di un gruppo cristallografico). \\

So che $m(\vb{A}) > m^{\perp}(\vb{A})$ se  $\vb{A} \neq id$. \\
$\forall \vb{u} \in E_{\vb{A}}$ vettore unitario, \\ $\epsilon := \frac{1}{8} \bigg( m(\vb{A}) - m^{\perp}(\vb{A}) \bigg)$  \\ed applico il teorema Mini Bieberbach. \\
\[ \exists \beta \in \Gamma : m(\vb{B}) \leq \epsilon ; \vb{b} \neq 0 ; \angle(\vb{u, b})  \leq \delta \]
In particolare scelgo $\delta $ in modo da avere $\norm{\vb{b}^{\perp}} \leq \norm{\vb{b}^E}$, posso farlo come da figura. \\
Fra questi $\beta$ scelgo quello per cui $\norm{\vb{b}}$ è minimo ($\neq 0$, posso farlo per la prima proprietà dei gruppi cristallografici). \\
Osservo che, se $\beta$ non è una traslazione, allora \\
$ \norm{\vb{b}} \geq \norm{\vb{a}}$, questo perché $m(\vb{B}) \leq \frac{1}{8}m(\vb{A}) \leq \frac{1}{4}$ e $\alpha$ è stato scelto fra le isometrie in $\Gamma$ con in modo da minimizzare il modulo della componente traslatoria).  
\end{minipage} \hfill
\begin{minipage}{0.5\textwidth}
\begin{tikzpicture}
  \coordinate (O) at (0,0);
  \coordinate (A) at (3,5);
  \coordinate (B) at (0,4);
  \coordinate (C) at (1.5,5);
  \draw[dashed] (-3,0) -- (3,0)node[right] {$E^{\perp}_{\vb{A}}$};
  \draw[dashed] (1.5,0) |- (0,5);
  \draw[vector, red, thick] (O) -- (1.5,0)node[below] {$\vb{b}^{\perp}$};
  \draw[vector, red, thick] (O) -- (0,5)node[left] {$\vb{b}^{E}$};
  \draw[thick] (0,-2) -- (0,5.5)node[above] {$E_{\vb{A}}$};
  \draw[vector] (O) -- (B)node[right] {$\vb{u}$};
  \draw[vector] (O) -- (C)node[right] {$\vb{b}$};
  \draw[blue, thick] (0,0) -- (3,5);
  \draw[blue, thick] (0,0) -- (-3,5);
  \filldraw[black] (0,0) circle (2pt);
  \pic[draw,"$\delta$",angle radius=30,angle eccentricity=1.25] {angle=A--O--B};  
  \begin{scope}[on background layer]
		\fill[blue!20] (0,0) -- (-3,5) -- (3,5) -- cycle;
  \end{scope}
\end{tikzpicture}
\end{minipage}
Definisco una nuova isometria $ \tilde{\beta} := [\vb{\alpha,\beta}] \in \Gamma$  \\
So dal lemma 1.3 e dal lemma1.10 che
\[ m(\tilde{B} ) = m[\vb{A,B}] \leq 2m(\vb{A}) m(\vb{B}) \leq 2 \frac{1}{2}m(\vb{B}) = m(\vb{B}) \]
\[ trans( \tilde{\beta}) = \vb{(A-id)b + (id-[A,B])b + A(id-B)A^{-1}a} = \vb{(A-id)b + r}\]
Con $\vb{r} = \vb{(id-\tilde{B})b + A(id-B)A^{-1}a}$ e $\tilde{\vb{b}}^{\perp} =  \vb{(A-id)b^{\perp} + r}$.
\begin{itemize}
\item Se $\beta$  è una translazione $\Longrightarrow \vb{B = id = \tilde{B}} \Longrightarrow \vb{r} = 0$. 
\item Se $\beta$ non è una translazione $\Longrightarrow \norm{\vb{b}} \geq \norm{\vb{a}}$  e quindi \\
\[ \norm{\vb{r}} \leq m(\tilde{\vb{B}}) \norm{\vb{b}} + m(\vb{B}) \norm{\vb{a}} \leq \big( m(\tilde{\vb{B}}) + m(\vb{B}) \big) \norm{\vb{b}} \leq 2m(\vb{B})(\vb{b^{E}+ b^{\perp}}) < 4 m(\vb{B}) \norm{\vb{b}^{E}} \leq \frac{1}{2} \big( m(\vb{A}) - m^{\perp}(\vb{A}) \big)\norm{\vb{b}^{E}} \]
\end{itemize}
In entrambi i casi ho che $\norm{\vb{r}} < \frac{1}{2} \big( m(\vb{A}) - m^{\perp}(\vb{A}) \big)\norm{\vb{b}^{E}}$. \\
Posso scrivere 
\[ \tilde{\vb{b}}^{E} -(\vb{A-id) b}^{E} - \vb{r}^{E} = (\vb{A-id) b}^{\perp} + \vb{r}^{\perp} - \tilde{\vb{b}}^{\perp} = 0 \]
Usando la caratterizzazione $\norm{\vb{b}^{\perp}} \leq \norm{\vb{b}^E}$  ottengo
\[ \norm{\tilde{\vb{b}}^{\perp}} \leq  m^{\perp}(\vb{A}) \norm{\vb{b}^{\perp}} + \norm{\vb{r}^{\perp}} < m^{\perp}(\vb{A}) \norm{\vb{b}^{E}} + \frac{1}{2} \big( m(\vb{A}) - m(\vb{A}^{\perp}) \big)\norm{\vb{b}^{E}}  \] 
Sommando a destra ottengo
\[ \norm{\tilde{\vb{b}}^{\perp}} < \frac{1}{2} \big( m(\vb{A}) + m(\vb{A}^{\perp}) \big) \]
D'altro canto, utilizzanzo la disuguaglianza triangolare inversa, posso scrivere
\[ \norm{\vb{b}^{E}} = \norm{(\vb{A-id) b}^{E} + \vb{r}^{E}} \geq \bigg| m(A) \norm{\vb{b}^E} - \norm{\vb{r}}\bigg| > m(\vb{A}) \norm{\vb{b}^E} - \frac{1}{2} \bigg( m(\vb{A}) - m^{\perp}(\vb{A})\bigg)\norm{\vb{b}^E} =  \frac{1}{2} \big( m(\vb{A}) + m(\vb{A}^{\perp}) \big)\]
In particolare quindi 
\[ \norm{\vb{b}^{E}} > \norm{\vb{b}^{\perp}}\]
So inoltre che 
\[ \norm{\tilde{\vb{b}}} \leq m(\vb{A}) \norm{\vb{b}} + \norm{\vb{r}} < m(\vb{A})\norm{\vb{b}} + \frac{1}{2} \big( m(\vb{A}) - m^{\perp}(\vb{A}) \big)\norm{\vb{b}^{E}} \leq  \norm{\vb{b}} \bigg( \frac{1}{2} + \frac{1}{4}\bigg) < \norm{\vb{b}} \]
Ho un assurdo perché $\beta$ era stato scelto fra tutti quelli che soddisfavano le condizioni in modo da minimizzare la norma di $b$.


\end{proof}

\section{Dimostrazione}


FINIRE DIMOSTRAZIONE DEL PRIMO TEO DI BIEB

\section{Secondo teorema di Bieberbach}

\begin{definition}
Un reticolo $L$ è un gruppo cristallografico che contiene solo translazioni. \\
Gli elementi di $L$ possono essere identificati con i vettori di $\mathbb{R}^n$ corrispondenti alla propria componenete di translazione e vengono chiamati punti di reticolo. 
\end{definition}

Dato un elemento $\omega \in L$, per abuso di notazione scriveremo $\omega = trans(\omega) = \vb{w}$. 
Enuncio il seguente risultato senza dimostrarlo.
\begin{lemma}
Ogni reticolo $L$ di dimensione $n$ è isomorfo a $\mathbb{Z}^n$. \\
Di conseguenza $L$ è abeliano e la distanza minima fra due punti di reticolo coincide con la lunghezza del minimo vettore non nullo in $L$.  
\end{lemma}

\begin{lemma}
Sia $L$ un reticolo in $\mathbb{E}^n$ i cui vettori abbiano distanza a coppie $\geq 1$. \\
Sia $\rho >0$, chiamo $N(\rho)$ il numero di punti di reticolo in $L$ con distanza dall'origine $\leq \rho$. 
\[ N(\rho) \leq (2 \rho +1)^n\]
\end{lemma}
\begin{proof}
Per ogni punto di reticolo a distanza inferiore o uguale di $\rho$ dall'origine posso considerare una palla aperta $n$-dimensionale centrata in esso e di raggio $\frac{1}{2}$. Queste palle sono sicuramente disgiunte in quanto la distanzza fra due punti del reticolo è superiore al doppio dei raggi; sono inoltre tutte contenute nella palla $n$-dimensionale centrata nell'orgine di raggio $ \rho + \frac{1}{2}$. 
Il volume della palla centrata nell'origine è sicuramente superiore alla somma dei volumi delle singole palle di raggio $\frac{1}{2}$, confrontando i volumi ottengo

\[ N(\rho) \bigg(  \frac{1}{2} \bigg) \leq \bigg( \rho + \frac{1}{2} \bigg) \]
\[ N(\rho) \leq \bigg( 2 \rho + 1 \bigg)\]
\end{proof}

\begin{lemma}
Sia $L$ un reticolo in $\mathbb{E}^n$ i cui vettori abbiano distanza a coppie $\geq 1$. \\; consideriamo un sottospazio lineare di $\mathbb{R}^n$ generato da $k$ vettori $\vb{w}_i \in L$ con $i = 1,... ,k$. \\
Se un punto di reticolo $\vb{w} \in L$ non è contenuto in $E$, allora la sua componenete in $E^{\perp}$ è tale che 
\[ \norm{\vb{w}^{\perp}} \geq \bigg( 3 +  \sum_{i = 1}^{k} \norm{\vb{w}_i} \bigg)^{-n} \]
\end{lemma}

\begin{proof}
Sia \hfill \[ N = \left\lfloor
\bigg( 3 +  \sum_{i = 1}^{k} \norm{\vb{w}_i} \bigg)^{n}
\right\rfloor\]. \\
Suppongo per assurdo che $0 < \norm{\vb{w}^{\perp}}  < \frac{1}{N}$. \\
In questa situazione ho che i vettori $j \vb{w}$ con $j = 0, ..., N$ hanno distanze da $E$ inferiori a 1. 
Aggiungendo ad ognuno di questi vettori una combinazione lineare di $\vb{w}_k$ posso 
\end{proof}

\end{document}
